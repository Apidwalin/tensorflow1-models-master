{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\APIDWA~1\\AppData\\Local\\Temp/ipykernel_9872/1794385767.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = '/home/jackon/captcha-tensorflow/images/char-4-epoch-6/train'  # 30241 images. validate accuracy: 87.6%\n",
    "DATA_DIR = '/home/jackon/captcha-tensorflow/images/char-4-epoch-60/train'  # 302410 images. validate accuracy: 98.8%\n",
    "H, W, C = 100, 120, 3\n",
    "N_LABELS = 10\n",
    "D = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_filepath(filepath):\n",
    "    try:\n",
    "        path, filename = os.path.split(filepath)\n",
    "        filename, ext = os.path.splitext(filename)\n",
    "        label, _ = filename.split(\"_\")\n",
    "        return label\n",
    "    except Exception as e:\n",
    "        print('error to parse %s. %s' % (filepath, e))\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pandas data frame of images, age, gender and race\n",
    "files = glob.glob(os.path.join(DATA_DIR, \"*.png\"))\n",
    "attributes = list(map(parse_filepath, files))\n",
    "\n",
    "df = pd.DataFrame(attributes)\n",
    "df['file'] = files\n",
    "df.columns = ['label', 'file']\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.random.permutation(len(df))\n",
    "train_up_to = int(len(df) * 0.7)\n",
    "train_idx = p[:train_up_to]\n",
    "test_idx = p[train_up_to:]\n",
    "\n",
    "# split train_idx further into training and validation set\n",
    "train_up_to = int(train_up_to * 0.7)\n",
    "train_idx, valid_idx = train_idx[:train_up_to], train_idx[train_up_to:]\n",
    "\n",
    "print('train count: %s, valid count: %s, test count: %s' % (\n",
    "    len(train_idx), len(valid_idx), len(test_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def get_data_generator(df, indices, for_training, batch_size=16):\n",
    "    images, labels = [], []\n",
    "    while True:\n",
    "        for i in indices:\n",
    "            r = df.iloc[i]\n",
    "            file, label = r['file'], r['label']\n",
    "            im = Image.open(file)\n",
    "#             im = im.resize((H, W))\n",
    "            im = np.array(im) / 255.0\n",
    "            images.append(np.array(im))\n",
    "            labels.append(np.array([np.array(to_categorical(int(i), N_LABELS)) for i in label]))\n",
    "            if len(images) >= batch_size:\n",
    "#                 print(np.array(images), np.array(labels))\n",
    "                yield np.array(images), np.array(labels)\n",
    "                images, labels = [], []\n",
    "        if not for_training:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Conv2D, MaxPool2D, GlobalMaxPool2D, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_layer = tf.keras.Input(shape=(H, W, C))\n",
    "x = layers.Conv2D(32, 3, activation='relu')(input_layer)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# x = layers.Dropout(0.5)(x)\n",
    "\n",
    "x = layers.Dense(D * N_LABELS, activation='softmax')(x)\n",
    "x = layers.Reshape((D, N_LABELS))(x)\n",
    "\n",
    "model = models.Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics= ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "batch_size = 64\n",
    "valid_batch_size = 64\n",
    "train_gen = get_data_generator(df, train_idx, for_training=True, batch_size=batch_size)\n",
    "valid_gen = get_data_generator(df, valid_idx, for_training=True, batch_size=valid_batch_size)\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"./model_checkpoint\", monitor='val_loss')\n",
    "]\n",
    "\n",
    "history = model.fit(train_gen,\n",
    "                    steps_per_epoch=len(train_idx)//batch_size,\n",
    "                    epochs=5,\n",
    "#                     callbacks=callbacks,\n",
    "                    validation_data=valid_gen,\n",
    "                    validation_steps=len(valid_idx)//valid_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def  plot_train_history(history):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "    axes[0].plot(history.history['accuracy'], label='Train accuracy')\n",
    "    axes[0].plot(history.history['val_accuracy'], label='Val accuracy')\n",
    "    axes[0].set_xlabel('Epochs')\n",
    "    axes[0].legend() \n",
    "\n",
    "    axes[1].plot(history.history['loss'], label='Training loss')\n",
    "    axes[1].plot(history.history['val_loss'], label='Validation loss')\n",
    "    axes[1].set_xlabel('Epochs')\n",
    "    axes[1].legend()\n",
    "\n",
    "plot_train_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = get_data_generator(df, test_idx, for_training=False, batch_size=128)\n",
    "dict(zip(model.metrics_names, model.evaluate(test_gen, steps=len(test_idx)//128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = get_data_generator(df, test_idx, for_training=False, batch_size=128)\n",
    "x_test, y_test = next(test_gen)\n",
    "\n",
    "y_pred = model.predict_on_batch(x_test)\n",
    "\n",
    "y_true = tf.math.argmax(y_test, axis=-1)\n",
    "y_pred = tf.math.argmax(y_pred, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "n = 30\n",
    "random_indices = np.random.permutation(n)\n",
    "n_cols = 5\n",
    "n_rows = math.ceil(n / n_cols)\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 20))\n",
    "for i, img_idx in enumerate(random_indices):\n",
    "    ax = axes.flat[i]\n",
    "    ax.imshow(x_test[img_idx])\n",
    "    ax.set_title('pred: {}'.format(\n",
    "        ''.join(map(str, y_pred[img_idx].numpy()))))\n",
    "    ax.set_xlabel('true: {}'.format(\n",
    "        ''.join(map(str, y_true[img_idx].numpy()))))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
